{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "from keras.regularizers import L1, L2\n",
    "from keras.metrics import CategoricalCrossentropy, MeanSquaredError, CategoricalAccuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = 'dataset-HAR-PUC-Rio.csv'\n",
    "OUTPUT_FILE = 'A2, E.txt'\n",
    "DELIM = ';'\n",
    "\n",
    "HIDDEN_LAYER_NODES = 22\n",
    "OUT_NODES = 5\n",
    "\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 38\n",
    "\n",
    "MOMENTUM = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "REGULATION=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def underSample(df): # underSamples our dataset\n",
    "    class_1 = df[df['class'] == 1]\n",
    "    class_2 = df[df['class'] == 2]\n",
    "    class_3 = df[df['class'] == 3]\n",
    "    class_4 = df[df['class'] == 4]\n",
    "    class_5 = df[df['class'] == 5]\n",
    "\n",
    "    def getMinimunNumber(numbers):\n",
    "        return min(numbers)\n",
    "    \n",
    "    min_count = getMinimunNumber([class_1['class'].count(), class_2['class'].count(\n",
    "    ), class_3['class'].count(), class_4['class'].count(), class_5['class'].count()])\n",
    "    \n",
    "    # pick random samples from classes 1 - 5 (cause there is a big difference between them)\n",
    "    class_1 = class_1.sample(min_count)\n",
    "    class_2 = class_2.sample(min_count)\n",
    "    class_3 = class_3.sample(min_count)\n",
    "    class_4 = class_4.sample(min_count)\n",
    "    class_5 = class_5.sample(min_count)\n",
    "\n",
    "    return_df = pd.concat(\n",
    "        [class_1, class_2, class_3, class_4, class_5], ignore_index=True)\n",
    "\n",
    "    return return_df\n",
    "\n",
    "\n",
    "def import_from_csv_and_change_values():\n",
    "    imported_df = pd.read_csv(\n",
    "        INPUT_FILE, delimiter=DELIM, low_memory=False)\n",
    "    # --------------------------------------------\n",
    "    # Woman = 1\n",
    "    # Man = 2\n",
    "    # x values = [-617,533]\n",
    "    #\n",
    "    # class values will be transformed to (1,2,3,4,5)\n",
    "    # sittingdown = 1\n",
    "    # standingup = 2\n",
    "    # standing = 3\n",
    "    # walking = 4\n",
    "    # sitting = 5\n",
    "    # --------------------------------------------\n",
    "    imported_df.replace({'gender': {\"Woman\": 1, \"Man\": 2}}, inplace=True)\n",
    "    imported_df.replace({'class': {\n",
    "        \"sittingdown\": 1,\n",
    "        \"standingup\": 2,\n",
    "        \"standing\": 3,\n",
    "        \"walking\": 4,\n",
    "        \"sitting\": 5\n",
    "    }}, inplace=True)\n",
    "    imported_df.replace(',', '.', inplace=True, regex=True)\n",
    "\n",
    "    imported_df['how_tall_in_meters'] = imported_df['how_tall_in_meters'].astype(\n",
    "        float)\n",
    "    imported_df['body_mass_index'] = imported_df['body_mass_index'].astype(\n",
    "        float)\n",
    "\n",
    "    # remove unnecessary data from dataframe\n",
    "    imported_df = imported_df.drop('user', axis='columns')\n",
    "    imported_df = underSample(imported_df)\n",
    "    return imported_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve Info and change it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve information and save it\n",
    "start_dataframe = import_from_csv_and_change_values()\n",
    "print(\"Data reached and ready!\")\n",
    "\n",
    "norm_dataset = start_dataframe.to_numpy()\n",
    "X = norm_dataset[:, :-1]\n",
    "y = norm_dataset[:, -1]\n",
    "\n",
    "X = QuantileTransformer().fit_transform(X)\n",
    "\n",
    "encoder = LabelEncoder().fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(encoded_Y)\n",
    "print(\"Y converted to categorical variables!\")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "print(\"KFolds done! Starting with cross validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold = 0\n",
    "\n",
    "scores_mse = []\n",
    "scores_accuracy = []\n",
    "scores_CE = []\n",
    "\n",
    "print(f\"HIDDEN_LAYER_NODES={HIDDEN_LAYER_NODES}   OUT_NODES = {OUT_NODES}   EPOCHS={EPOCHS}   BATCH_SIZE={BATCH_SIZE}\")\n",
    "for train, test in kfold.split(X):\n",
    "    fold += 1\n",
    "\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(HIDDEN_LAYER_NODES, input_dim=17, activation='relu', activity_regularizer=L2(REGULATION)))\n",
    "    model.add(Dense(OUT_NODES, input_dim=HIDDEN_LAYER_NODES, activation='softmax', activity_regularizer=L2(REGULATION)))\n",
    "\n",
    "    metrics = [\n",
    "        CategoricalAccuracy(name='ACC'),\n",
    "        MeanSquaredError(name='MSE'),\n",
    "        CategoricalCrossentropy(name='CE')\n",
    "    ]\n",
    "\n",
    "    res = model.compile(loss='categorical_crossentropy', optimizer=Nadam(learning_rate=LEARNING_RATE, use_ema=True, ema_momentum=MOMENTUM), metrics=metrics)\n",
    "    \n",
    "    earlyStop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=0, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[earlyStop])\n",
    "    \n",
    "    pred = model.evaluate(X_test, y_test, use_multiprocessing=True, workers=4, verbose=2)\n",
    "\n",
    "    score_mse = pred[2]\n",
    "    scores_mse.append(score_mse)\n",
    "    \n",
    "    score_accuracy = pred[1]\n",
    "    scores_accuracy.append(score_accuracy)\n",
    "    \n",
    "    score_CE = pred[3]\n",
    "    scores_CE.append(score_CE)\n",
    "    \n",
    "    print(f\"#Fold {fold}    (MSE): {round(score_mse, 5)}    (Accuracy): {round(score_accuracy, 5)}    (CE): {round(score_CE, 5)}\")\n",
    "\n",
    "print(f\"\\nFinal, out of sample    (MSE): {round(np.mean(scores_mse), 5)}    (Accuracy): {round(np.mean(scores_accuracy), 5)}    (CE): {round(np.mean(scores_CE), 5)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
